{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# coco.data内容（修改）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "parse_data_config()的解析代码来看，可以通过“#”來注释行内容\n",
    "为什么路径有“..”？因为作者原来的coco数据集是放在和程序同一个父目录下的，所以..跳出程序的目录，在父目录进入数据集文件\n",
    "'''\n",
    "classes=80\n",
    "train=../coco/trainvalno5k.txt  #存放的图片路径\n",
    "valid=../coco/5k.txt            #测试集图片路径\n",
    "names=data/coco.names           #coco类别名\n",
    "backup=backup/\n",
    "eval=coco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parse_data_config()解析coco.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'gpus': '0,1,2,3', \n",
    " 'num_workers': '10', \n",
    " 'classes': '80', \n",
    " 'train': '../coco/trainvalno5k.txt', \n",
    " 'valid': '../coco/5k.txt', \n",
    " 'names': 'data/coco.names', \n",
    " 'backup': 'backup/', \n",
    " 'eval': 'coco'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataloader的剖析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dataset.py文件内，类似图片的加载，这里也使用了一个类class load_images_and_labels()，比较复杂。\n",
    "这里值展示一些中间变量，主要参见github的注释\n",
    "为了展示方便，我把检测图片换成了自己标注的30张小轿车图片，以下均如此\n",
    "'''\n",
    "\n",
    "class load_images_and_labels():  \n",
    "    def __init__(self, path, batch_size=1, img_size=608, multi_scale=False, augment=False):\n",
    "        self.path = path\n",
    "        with open(path, 'r') as file:\n",
    "            self.img_files = file.readlines()\n",
    "\n",
    "        self.img_files = [path.replace('\\n', '') for path in self.img_files]\n",
    "        '''\n",
    "        ['/py/pic/JPEGImages/1.jpg', \n",
    "        '/py/pic/JPEGImages/2.jpg', \n",
    "        '/py/pic/JPEGImages/3.jpg', \n",
    "            ...\n",
    "        '/py/pic/JPEGImages/30.jpg']不要留空行，否则也会作为元素存进去\n",
    "        '''\n",
    "        self.label_files = [path.replace('images', 'labels').replace('.png', '.txt').replace('.jpg', '.txt') for path in\n",
    "                            self.img_files]\n",
    "        '''\n",
    "        ['/py/pic/JPEGImages/1.txt', \n",
    "        '/py/pic/JPEGImages/2.txt',\n",
    "            ...\n",
    "        '/py/pic/JPEGImages/30.txt']\n",
    "        '''\n",
    "        self.nF = len(self.img_files)  # number of image files\n",
    "        self.nB = math.ceil(self.nF / batch_size)  # number of batches\n",
    "        self.batch_size = batch_size\n",
    "        self.height = img_size\n",
    "        self.multi_scale = multi_scale\n",
    "        self.augment = augment\n",
    "\n",
    "        assert self.nB > 0, 'No images found in path %s' % path\n",
    "\n",
    "        # RGB normalization values\n",
    "        # self.rgb_mean = np.array([60.134, 49.697, 40.746], dtype=np.float32).reshape((1, 3, 1, 1))\n",
    "        # self.rgb_std = np.array([29.99, 24.498, 22.046], dtype=np.float32).reshape((1, 3, 1, 1))\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.count = -1\n",
    "        self.shuffled_vector = np.random.permutation(self.nF) if self.augment else np.arange(self.nF)\n",
    "        '''\n",
    "        if  not  self.augment:\n",
    "        [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
    "        if  self.augment:\n",
    "        [ 2 28 13 10 26 24 27 11 17 22  5 16  8 14 23 20  1 29  6  4 18 19  9  7 25  3  0 21 15 12]\n",
    "        '''\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        self.count += 1\n",
    "        if self.count == self.nB:\n",
    "            raise StopIteration\n",
    "\n",
    "        ia = self.count * self.batch_size\n",
    "        ib = min((self.count + 1) * self.batch_size, self.nF)\n",
    "\n",
    "        if self.multi_scale:\n",
    "            # Multi-Scale YOLO Training\n",
    "            height = random.choice(range(10, 20)) * 32  # 320 - 608 pixels\n",
    "        else:\n",
    "            # Fixed-Scale YOLO Training\n",
    "            height = self.height\n",
    "\n",
    "        img_all = []\n",
    "        labels_all = []\n",
    "        for index, files_index in enumerate(range(ia, ib)):\n",
    "            img_path = self.img_files[self.shuffled_vector[files_index]]\n",
    "            label_path = self.label_files[self.shuffled_vector[files_index]]\n",
    "\n",
    "            img = cv2.imread(img_path)  # BGR\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            augment_hsv = True\n",
    "            if self.augment and augment_hsv:\n",
    "                # SV augmentation by 50%\n",
    "                fraction = 0.50\n",
    "                img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "                S = img_hsv[:, :, 1].astype(np.float32)\n",
    "                V = img_hsv[:, :, 2].astype(np.float32)\n",
    "\n",
    "                a = (random.random() * 2 - 1) * fraction + 1\n",
    "                S *= a\n",
    "                if a > 1:\n",
    "                    np.clip(S, a_min=0, a_max=255, out=S)\n",
    "\n",
    "                a = (random.random() * 2 - 1) * fraction + 1\n",
    "                V *= a\n",
    "                if a > 1:\n",
    "                    np.clip(V, a_min=0, a_max=255, out=V)\n",
    "\n",
    "                img_hsv[:, :, 1] = S.astype(np.uint8)\n",
    "                img_hsv[:, :, 2] = V.astype(np.uint8)\n",
    "                cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR, dst=img)\n",
    "\n",
    "            h, w, _ = img.shape\n",
    "            img, ratio, padw, padh = resize_square(img, height=height, color=(127.5, 127.5, 127.5))\n",
    "\n",
    "            # Load labels\n",
    "            if os.path.isfile(label_path):\n",
    "                labels0 = np.loadtxt(label_path, dtype=np.float32).reshape(-1, 5)\n",
    "\n",
    "                # Normalized xywh to pixel xyxy format\n",
    "                labels = labels0.copy()\n",
    "                labels[:, 1] = ratio * w * (labels0[:, 1] - labels0[:, 3] / 2) + padw\n",
    "                labels[:, 2] = ratio * h * (labels0[:, 2] - labels0[:, 4] / 2) + padh\n",
    "                labels[:, 3] = ratio * w * (labels0[:, 1] + labels0[:, 3] / 2) + padw\n",
    "                labels[:, 4] = ratio * h * (labels0[:, 2] + labels0[:, 4] / 2) + padh\n",
    "            else:\n",
    "                labels = np.array([])\n",
    "\n",
    "            # Augment image and labels\n",
    "            if self.augment:\n",
    "                img, labels, M = random_affine(img, labels, degrees=(-5, 5), translate=(0.10, 0.10), scale=(0.90, 1.10))\n",
    "\n",
    "            plotFlag = False\n",
    "            if plotFlag:\n",
    "                import matplotlib.pyplot as plt\n",
    "                plt.figure(figsize=(10, 10)) if index == 0 else None\n",
    "                plt.subplot(4, 4, index + 1).imshow(img[:, :, ::-1])\n",
    "                plt.plot(labels[:, [1, 3, 3, 1, 1]].T, labels[:, [2, 2, 4, 4, 2]].T, '.-')\n",
    "                plt.axis('off')\n",
    "\n",
    "            nL = len(labels)\n",
    "            if nL > 0:\n",
    "                # convert xyxy to xywh\n",
    "                labels[:, 1:5] = xyxy2xywh(labels[:, 1:5].copy()) / height\n",
    "\n",
    "            if self.augment:\n",
    "                # random left-right flip\n",
    "                lr_flip = True\n",
    "                if lr_flip & (random.random() > 0.5):\n",
    "                    img = np.fliplr(img)\n",
    "                    if nL > 0:\n",
    "                        labels[:, 1] = 1 - labels[:, 1]\n",
    "\n",
    "                # random up-down flip\n",
    "                ud_flip = False\n",
    "                if ud_flip & (random.random() > 0.5):\n",
    "                    img = np.flipud(img)\n",
    "                    if nL > 0:\n",
    "                        labels[:, 2] = 1 - labels[:, 2]\n",
    "            #对一张图片遍历结束，列表存入图片信息矩阵和一个包含这张图所有gt的张量，看下面的全部打印输出即可知\n",
    "            img_all.append(img)\n",
    "            labels_all.append(torch.from_numpy(labels))\n",
    "\n",
    "        # Normalize\n",
    "        img_all = np.stack(img_all)[:, :, :, ::-1].transpose(0, 3, 1, 2)  # BGR to RGB and cv2 to pytorch\n",
    "        img_all = np.ascontiguousarray(img_all, dtype=np.float32)\n",
    "        # img_all -= self.rgb_mean\n",
    "        # img_all /= self.rgb_std\n",
    "        img_all /= 255.0\n",
    "\n",
    "        return torch.from_numpy(img_all), labels_all\n",
    "        '''\n",
    "        看看返回全部图片的信息：\n",
    "        首先是torch.from_numpy(img_all)的张量维度：torch.Size([30, 3, 416, 416])，30张图片较好理解\n",
    "        然后是label:\n",
    "        [tensor([[0.00000, 0.67837, 0.73789, 0.05795, 0.04066],\n",
    "                 [0.00000, 0.83071, 0.70716, 0.06600, 0.03726]]), \n",
    "         tensor([[0.00000, 0.90200, 0.44104, 0.05873, 0.04905],\n",
    "                 [0.00000, 0.87276, 0.46533, 0.06384, 0.05178],\n",
    "                 [0.00000, 0.76982, 0.52693, 0.05216, 0.05285]]), \n",
    "         ...\n",
    "         tensor([[0.00000, 0.88917, 0.21438, 0.07863, 0.03844],\n",
    "                 [0.00000, 0.91443, 0.32260, 0.08621, 0.04365],\n",
    "                 [0.00000, 0.90650, 0.36637, 0.10071, 0.04244],\n",
    "                 [0.00000, 0.73085, 0.45161, 0.05084, 0.06293],\n",
    "                 [0.00000, 0.75494, 0.53112, 0.05614, 0.05986],\n",
    "                 [0.00000, 0.78969, 0.61730, 0.06548, 0.06405],\n",
    "                 [0.00000, 0.68837, 0.35550, 0.09051, 0.05555],\n",
    "                 [0.00000, 0.46658, 0.41092, 0.09667, 0.03519],\n",
    "                 [0.00000, 0.14835, 0.43208, 0.10331, 0.05653]])]\n",
    "          可以看出，每个张量包含一张图片的gt内容，第一张图片有两个gt，信息分别是cxywh（经过416归一化）\n",
    "          显然，列表长度为30\n",
    "        '''\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.nB  # number of batches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for batch_i, (imgs, targets) in enumerate(dataloader):\n",
    "\n",
    "        with torch.no_grad():   #不追踪梯度\n",
    "            #通过model(img)自动调用Module类的forward方法计算损失，该步骤放到gpu计算\n",
    "            output = model(imgs.to(device))     \n",
    "            output = non_max_suppression(output, conf_thres=conf_thres, nms_thres=nms_thres)\n",
    "\n",
    "        # Compute average precision for each sample\n",
    "        for sample_i, (labels, detections) in enumerate(zip(targets, output)):\n",
    "            correct = []\n",
    "\n",
    "            if detections is None:\n",
    "                # If there are no detections but there are labels mask as zero AP\n",
    "                if labels.size(0) != 0:\n",
    "                    mAPs.append(0), mR.append(0), mP.append(0)\n",
    "                continue\n",
    "\n",
    "            # Get detections sorted by decreasing confidence scores\n",
    "            detections = detections.cpu().numpy()\n",
    "            detections = detections[np.argsort(-detections[:, 4])]\n",
    "\n",
    "            # If no labels add number of detections as incorrect\n",
    "            if labels.size(0) == 0:\n",
    "                # correct.extend([0 for _ in range(len(detections))])\n",
    "                mAPs.append(0), mR.append(0), mP.append(0)\n",
    "                continue\n",
    "            else:\n",
    "                target_cls = labels[:, 0]\n",
    "\n",
    "                # Extract target boxes as (x1, y1, x2, y2)\n",
    "                target_boxes = xywh2xyxy(labels[:, 1:5]) * img_size\n",
    "\n",
    "                detected = []\n",
    "                for *pred_bbox, conf, obj_conf, obj_pred in detections:\n",
    "\n",
    "                    pred_bbox = torch.FloatTensor(pred_bbox).view(1, -1)\n",
    "                    # Compute iou with target boxes\n",
    "                    iou = bbox_iou(pred_bbox, target_boxes)\n",
    "                    # Extract index of largest overlap\n",
    "                    best_i = np.argmax(iou)\n",
    "                    # If overlap exceeds threshold and classification is correct mark as correct\n",
    "                    if iou[best_i] > iou_thres and obj_pred == labels[best_i, 0] and best_i not in detected:\n",
    "                        correct.append(1)\n",
    "                        detected.append(best_i)\n",
    "                    else:\n",
    "                        correct.append(0)\n",
    "\n",
    "            # Compute Average Precision (AP) per class\n",
    "            AP, AP_class, R, P = ap_per_class(tp=correct, conf=detections[:, 4], pred_cls=detections[:, 6],\n",
    "                                              target_cls=target_cls)\n",
    "\n",
    "            # Accumulate AP per class\n",
    "            AP_accum_count += np.bincount(AP_class, minlength=nC)\n",
    "            AP_accum += np.bincount(AP_class, minlength=nC, weights=AP)\n",
    "\n",
    "            # Compute mean AP across all classes in this image, and append to image list\n",
    "            mAPs.append(AP.mean())\n",
    "            mR.append(R.mean())\n",
    "            mP.append(P.mean())\n",
    "\n",
    "            # Means of all images\n",
    "            mean_mAP = np.mean(mAPs)\n",
    "            mean_R = np.mean(mR)\n",
    "            mean_P = np.mean(mP)\n",
    "\n",
    "            # Print image mAP and running mean mAP\n",
    "            print(('%11s%11s' + '%11.3g' * 3) % (len(mAPs), dataloader.nF, mean_P, mean_R, mean_mAP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train和test的dataloader分析：for batch_i, (imgs, targets) in enumerate(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for batch_i, (imgs, targets) in enumerate(dataloader):\n",
    "        '''\n",
    "        imgs维度是张量：torch.Size([2, 3, 416, 416])，第一维度是batch_size数我这里设置的2\n",
    "        targets是列表：如[tensor([[0.00000, 0.67837, 0.73789, 0.05795, 0.04066],\n",
    "                                [0.00000, 0.83071, 0.70716, 0.06600, 0.03726]]), \n",
    "                        tensor([[0.00000, 0.90200, 0.44104, 0.05873, 0.04905],\n",
    "                                [0.00000, 0.87276, 0.46533, 0.06384, 0.05178],\n",
    "                                [0.00000, 0.76982, 0.52693, 0.05216, 0.05285]])]\n",
    "                    含有batch_size个张量的列表，每个张量含有二维数组，第0维是gt个数，第1维是一个gt的信息\n",
    "        '''\n",
    "        with torch.no_grad():\n",
    "            output = model(imgs.to(device))\n",
    "            '''\n",
    "            注意：这是在测试集上test效果，实际上也算是detect的一部分，思路和detect的前向传播一样\n",
    "            前向传播，output列表含2（batch_size）个张量，每个张量维度为torch.Size([10647, 85])\n",
    "            10647是三尺度合计预测的box数目；85是每个box的信息数目：80+4+1\n",
    "            '''\n",
    "            output = non_max_suppression(output, conf_thres=conf_thres, nms_thres=nms_thres)\n",
    "            '''\n",
    "            经过NMS，output列表显然还是两个张量元素，不过每个张量维度为torch.Size([31, 7]）因为抑制了部分重叠框\n",
    "            '''\n",
    "\n",
    "        # Compute average precision for each sample\n",
    "        for sample_i, (labels, detections) in enumerate(zip(targets, output)):\n",
    "            '''\n",
    "            将预测的输出和gt进行压缩\n",
    "            re：这个zip创建迭代对像是真的好用\n",
    "            zip(targets, output)是一个迭代对像，将目标压缩成元组形式，可通过list进行显示，如下只打印第一个元素zip(targets, output)[0]也就是第一张图片和他的box：\n",
    "                (tensor([[0.00000, 0.67837, 0.73789, 0.05795, 0.04066],[0.00000, 0.83071, 0.70716, 0.06600, 0.03726]]), \n",
    "                 tensor([[ 56.15526, 330.78809,  65.46760, 359.50897,   0.69717,   1.00000,   0.00000],\n",
    "                         [137.66658, 157.83122, 147.64067, 174.90404,   0.60628,   0.99516,   0.00000],\n",
    "                         [ 17.28005, 147.81779,  26.88957, 162.79787,   0.54086,   0.97253,   0.00000],\n",
    "                         ...\n",
    "                         [120.16389, 180.52190, 149.01424, 209.81590,   0.42977,   0.99791,   7.00000]], device='cuda:0'))\n",
    "            一个元组包含一张图片的gt张量和预测的box张量组成的信息\n",
    "\n",
    "            '''\n",
    "            correct = []\n",
    "\n",
    "            if detections is None:\n",
    "                # If there are no detections but there are labels mask as zero AP\n",
    "                if labels.size(0) != 0:\n",
    "                    mAPs.append(0), mR.append(0), mP.append(0)\n",
    "                continue\n",
    "\n",
    "            # Get detections sorted by decreasing confidence scores\n",
    "            detections = detections.cpu().numpy()\n",
    "            '''\n",
    "            对于一张图，这里的nms后生存下来的box信息维度，也就是detections维度为（31,7）的numpy矩阵\n",
    "            31是box数目，7是nms后85压缩到7个信息4+confidence+class_prob+class_label并且对于同一个标签内是按照confidence高到低排序的\n",
    "            [[     56.155      330.79      65.468      359.51     0.69717           1           0]\n",
    "             [     137.67      157.83      147.64       174.9     0.60628     0.99516           0]\n",
    "             [      17.28      147.82       26.89       162.8     0.54086     0.97253           0]\n",
    "              ...\n",
    "             [     120.16      180.52      149.01      209.82     0.42977     0.99791           7]]\n",
    "\n",
    "            '''\n",
    "            detections = detections[np.argsort(-detections[:, 4])]\n",
    "            '''\n",
    "            原来box是按照每个类标签内conf降序排列，下面转为所有类统一统计进行conf降序排列\n",
    "            '''\n",
    "            # If no labels add number of detections as incorrect\n",
    "            if labels.size(0) == 0:\n",
    "                # correct.extend([0 for _ in range(len(detections))])\n",
    "                mAPs.append(0), mR.append(0), mP.append(0)\n",
    "                continue\n",
    "            else:\n",
    "                target_cls = labels[:, 0]\n",
    "                '''\n",
    "                label的gt标注每个张量含有五个元素：c,x,y,w,h,如第一张图片\n",
    "                tensor([[0.00000, 0.67837, 0.73789, 0.05795, 0.04066],\n",
    "                        [0.00000, 0.83071, 0.70716, 0.06600, 0.03726]])\n",
    "                '''\n",
    "                # Extract target boxes as (x1, y1, x2, y2)\n",
    "                target_boxes = xywh2xyxy(labels[:, 1:5]) * img_size\n",
    "\n",
    "                detected = []\n",
    "                \n",
    "                '''detections维度还是（31,7）下面对一张图的每个预测的box进行遍历！'''\n",
    "                for *pred_bbox, conf, obj_conf, obj_pred in detections:\n",
    "                    '''\n",
    "                    这个*很6,很方便，*代表传递多个参数,会根据你遍历输入进行自动计算个数\n",
    "                    打印这四个变量看看输出：\n",
    "                    [4.786209, 313.84634, 53.00174, 353.85886]  0.99444515  0.99444515  0.839418  2.0\n",
    "                    可以看出7维数据刨去后面四个，剩下的直接整个作为列表传递给pred_bbox了\n",
    "                    '''\n",
    "                    \n",
    "                    pred_bbox = torch.FloatTensor(pred_bbox).view(1, -1)\n",
    "                    '''转为张量，并加了一维tensor([[  4.78621, 313.84634,  53.00174, 353.85886]])'''\n",
    "                    \n",
    "                    # Compute iou with target boxes\n",
    "                    iou = bbox_iou(pred_bbox, target_boxes)\n",
    "                    '''\n",
    "                    先看看输入：\n",
    "                    pred_bbox：      tensor([[  4.78621, 313.84634,  53.00174, 353.85886]]) （必然只有一个，因为是遍历）\n",
    "                    target_boxes:    tensor([[270.14755, 298.50504, 294.25320, 315.41931],   （有几个gt就是几维）\n",
    "                                             [331.84720, 286.42920, 359.30310, 301.92773]])\n",
    "                    输出：            tensor([0., 0.])      (我自己乱选的图片，iou为0正常)\n",
    "                    输出是：每个gt的target_boxes（如这里有两个）都要与所有预测出的（遍历的这个）box进行iou计算，输出得到和该图片gt中box数目相同长度的一维张量\n",
    "                    '''\n",
    "                    \n",
    "                    # Extract index of largest overlap\n",
    "                    best_i = np.argmax(iou)   '''取出最大iou的索引，常数：tensor(0)，也就是找出这个box应该属于哪个gt'''\n",
    "                    # If overlap exceeds threshold and classification is correct mark as correct\n",
    "                    if iou[best_i] > iou_thres and obj_pred == labels[best_i, 0] and best_i not in detected:\n",
    "                        correct.append(1)\n",
    "                        detected.append(best_i)\n",
    "                    else:\n",
    "                        correct.append(0)\n",
    "            '''所有预测的box遍历完毕，计算该张图片的ap'''\n",
    "            # Compute Average Precision (AP) per class\n",
    "            '''AP计算放在下个cell'''\n",
    "            AP, AP_class, R, P = ap_per_class(tp=correct, conf=detections[:, 4], pred_cls=detections[:, 6],\n",
    "                                              target_cls=target_cls)\n",
    "\n",
    "            # Accumulate AP per class\n",
    "            AP_accum_count += np.bincount(AP_class, minlength=nC)\n",
    "            AP_accum += np.bincount(AP_class, minlength=nC, weights=AP)\n",
    "\n",
    "            # Compute mean AP across all classes in this image, and append to image list\n",
    "            mAPs.append(AP.mean())\n",
    "            mR.append(R.mean())\n",
    "            mP.append(P.mean())\n",
    "\n",
    "            # Means of all images\n",
    "            mean_mAP = np.mean(mAPs)\n",
    "            mean_R = np.mean(mR)\n",
    "            mean_P = np.mean(mP)\n",
    "\n",
    "            # Print image mAP and running mean mAP\n",
    "            print(('%11s%11s' + '%11.3g' * 3) % (len(mAPs), dataloader.nF, mean_P, mean_R, mean_mAP))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AP计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''紧接上文，仍然在一张图片内'''\n",
    "\n",
    "def ap_per_class(tp, conf, pred_cls, target_cls):\n",
    "    # lists/pytorch to numpy\n",
    "    tp, conf, pred_cls, target_cls = np.array(tp), np.array(conf), np.array(pred_cls), np.array(target_cls)\n",
    "    '''\n",
    "    先看看这几个输入是什么：\n",
    "    tp：  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "          长度31,是NMS后剩下的31个预测box，通过iou和寻最大，找出每个box应该属于哪个gt，然后比较conf阈值和label，如果预测正确，加个1,不正确加个0，上面31个0说明预测全错误\n",
    "    \n",
    "    conf: [ 0.99445  0.99407   0.98948   0.97971   0.96331   0.91007  0.8762   0.84589  0.81772   0.81035   0.80608   0.80236 \n",
    "           0.76731  0.70668   0.69717   0.62326   0.62144   0.60628  0.59539  0.55832  0.54974   0.54384   0.54086   0.50405   \n",
    "           0.48564  0.42977   0.41794   0.40113   0.37924   0.37901  0.36003]\n",
    "          长度31,每个box按conf从大到小排列  \n",
    "    \n",
    "    pred_cls:[ 2 2 2 7 2 2 2 2 7 2 2 2 2 2 0 7 2 0 2 2 2 7 0 7 7 7 2 0 2 2 2]\n",
    "          对应box预测的label\n",
    "          \n",
    "    target_cls:[0 0]   gt的真实label    \n",
    "    '''\n",
    "    # Sort by objectness\n",
    "    i = np.argsort(-conf)\n",
    "    tp, conf, pred_cls = tp[i], conf[i], pred_cls[i]\n",
    "\n",
    "    # Find unique classes\n",
    "    '''\n",
    "    上面分析过pred_cls, target_cls均为一维向量，通过np.concatenate在第0维融合，相当于把整个target_cls列表添加到pred_cl后面\n",
    "    然后剔除重复的标签，留下唯一的class标签的行向量\n",
    "    '''\n",
    "    unique_classes = np.unique(np.concatenate((pred_cls, target_cls), 0))\n",
    "\n",
    "    # Create Precision-Recall curve and compute AP for each class\n",
    "    ap, p, r = [], [], []\n",
    "    for c in unique_classes:\n",
    "        i = pred_cls == c\n",
    "        '''（atten）为什么这里看似布尔量可以数值运算？因为是numpy.ndarray，而不是布尔，矩阵比较后可以计算'''\n",
    "        n_gt = sum(target_cls == c)  # Number of ground truth objects\n",
    "        n_p = sum(i)  # Number of predicted objects\n",
    "        '''\n",
    "        atten：这里是计算每类的AP，所以按类遍历\n",
    "        unique_classes=[0 2 7]\n",
    "        第一次循环c=0,寻找第一个类别:\n",
    "            i = pred_cls == c将预测的向量每个元素和遍历的类c进行比较，一样为真，得到pred_cls同维（31）的布尔向量\n",
    "                i=[False False False False False False False False False \n",
    "                   False False False False False  True False False  True \n",
    "                   False False False False  True False False False False  True False False False]；\n",
    "            sum(target_cls == c)将真实gt类别和当前遍历类进行比较，得到target_cls同维布尔向量，然后求和，表示的是真实gt中有几个是c这个类；\n",
    "                n_gt=2\n",
    "            n_p = sum(i)表示的是预测的box中有几个是这个c类\n",
    "                n_p=4\n",
    "        '''\n",
    "\n",
    "        if (n_p == 0) and (n_gt == 0):\n",
    "            continue\n",
    "        elif (n_p == 0) or (n_gt == 0):\n",
    "            ap.append(0)\n",
    "            r.append(0)\n",
    "            p.append(0)\n",
    "        else:\n",
    "            # Accumulate FPs and TPs\n",
    "            fpc = np.cumsum(1 - tp[i])\n",
    "            tpc = np.cumsum(tp[i])\n",
    "\n",
    "            # Recall\n",
    "            recall_curve = tpc / (n_gt + 1e-16)\n",
    "            r.append(tpc[-1] / (n_gt + 1e-16))\n",
    "\n",
    "            # Precision\n",
    "            precision_curve = tpc / (tpc + fpc)\n",
    "            p.append(tpc[-1] / (tpc[-1] + fpc[-1]))\n",
    "\n",
    "            # AP from recall-precision curve\n",
    "            ap.append(compute_ap(recall_curve, precision_curve))\n",
    "\n",
    "    return np.array(ap), unique_classes.astype('int32'), np.array(r), np.array(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
